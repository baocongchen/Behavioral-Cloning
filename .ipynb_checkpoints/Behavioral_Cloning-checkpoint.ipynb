{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7491, 20, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from skimage.exposure import adjust_gamma\n",
    "from drive import rgb2gray\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, ELU, Convolution2D, Lambda, Cropping2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.pooling import AveragePooling2D, MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from scipy import ndimage\n",
    "from scipy.misc import imresize\n",
    "\n",
    "\n",
    "# Get steering angles for controlled driving\n",
    "angles = pd.read_csv('./new_data/driving_log.csv', header=0)\n",
    "angles.columns = ('Center Image','Left Image','Right Image','Steering Angle','Throttle','Brake','Speed')\n",
    "angles = np.array(angles['Steering Angle'])\n",
    "\n",
    "# Create arrays for center images of controlled driving\n",
    "images = np.asarray(os.listdir('./new_data/IMG/'))\n",
    "center = np.ndarray(shape=(len(angles), 20, 64, 3))\n",
    "\n",
    "# Create controlled driving datasets\n",
    "# Images are resized to x64 to increase training speeds\n",
    "# The top 12 pixels are cropped off because they contain irrelevant information for training behavior\n",
    "# The final image size to be used in training is 20 x 64 x 1. \n",
    "count = 0\n",
    "angles_num = len(angles)\n",
    "for image in images:\n",
    "    image_file = os.path.join('./new_data/IMG', image)\n",
    "    if image.startswith('center'):\n",
    "        image_data = ndimage.imread(image_file).astype(np.float32)\n",
    "        center[count % angles_num] = imresize(image_data, (32,64,3))[12:,:,:]\n",
    "    count += 1\n",
    "\n",
    "\n",
    "X_train = center\n",
    "y_train = angles\n",
    "\n",
    "# Create a mirror image of the images in the dataset to prevent bias\n",
    "mirror = [X_train[0]]\n",
    "mirror_angles = [y_train[0]]\n",
    "for i in range(1, len(X_train)):\n",
    "    angle = y_train[i]\n",
    "    mirror_angles = np.append(mirror_angles, [angle * -1], axis=0)\n",
    "    mirror = np.append(mirror, [np.fliplr(X_train[i])], axis=0)\n",
    "print(mirror.shape)\n",
    "\n",
    "# Combine regular features/labels with mirror features/labels\n",
    "X_train = np.concatenate((X_train, mirror), axis=0)\n",
    "y_train = np.concatenate((y_train, mirror_angles),axis=0)\n",
    "\n",
    "# Perform train/test split to a create validation dataset\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "cropping2d_1 (Cropping2D)        (None, 14, 64, 3)     0           cropping2d_input_1[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)                (None, 14, 64, 3)     0           cropping2d_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 7, 32, 12)     588         lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 7, 32, 12)     0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 4, 16, 24)     1176        activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 4, 16, 24)     0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 2, 8, 36)      3492        activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 576)           0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 512)           295424      flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 512)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 512)           0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1)             513         dropout_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 301,193\n",
      "Trainable params: 301,193\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build model architecture\n",
    "# The image data is cropped and normalized to achieve the best prediction accuracy.\n",
    "model = Sequential()\n",
    "model.add(Cropping2D(((0,6),(0,0)), input_shape=(20, 64, 3)))\n",
    "model.add(Lambda(lambda x: (x / 127.5) - .5))\n",
    "model.add(Convolution2D(12, 4, 4, border_mode='same', subsample=(2,2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(24, 2, 2, border_mode='same', subsample=(2,2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(36, 2, 2, border_mode='same', subsample=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000: val_loss improved from inf to 0.02344, saving model to ./checkpoints/chk.00-0.02.hdf5\n",
      "Epoch 00001: val_loss improved from 0.02344 to 0.02103, saving model to ./checkpoints/chk.01-0.02.hdf5\n",
      "Epoch 00002: val_loss improved from 0.02103 to 0.01996, saving model to ./checkpoints/chk.02-0.02.hdf5\n",
      "Epoch 00003: val_loss improved from 0.01996 to 0.01947, saving model to ./checkpoints/chk.03-0.02.hdf5\n",
      "Epoch 00004: val_loss improved from 0.01947 to 0.01887, saving model to ./checkpoints/chk.04-0.02.hdf5\n",
      "Epoch 00005: val_loss improved from 0.01887 to 0.01846, saving model to ./checkpoints/chk.05-0.02.hdf5\n",
      "Epoch 00006: val_loss improved from 0.01846 to 0.01822, saving model to ./checkpoints/chk.06-0.02.hdf5\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 00008: val_loss improved from 0.01822 to 0.01792, saving model to ./checkpoints/chk.08-0.02.hdf5\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 00010: val_loss improved from 0.01792 to 0.01755, saving model to ./checkpoints/chk.10-0.02.hdf5\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 00012: val_loss improved from 0.01755 to 0.01739, saving model to ./checkpoints/chk.12-0.02.hdf5\n",
      "Epoch 00013: val_loss improved from 0.01739 to 0.01734, saving model to ./checkpoints/chk.13-0.02.hdf5\n",
      "Epoch 00014: val_loss improved from 0.01734 to 0.01720, saving model to ./checkpoints/chk.14-0.02.hdf5\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 00016: val_loss improved from 0.01720 to 0.01705, saving model to ./checkpoints/chk.16-0.02.hdf5\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 00018: val_loss improved from 0.01705 to 0.01663, saving model to ./checkpoints/chk.18-0.02.hdf5\n",
      "Epoch 00019: val_loss improved from 0.01663 to 0.01663, saving model to ./checkpoints/chk.19-0.02.hdf5\n",
      "Epoch 00020: val_loss improved from 0.01663 to 0.01662, saving model to ./checkpoints/chk.20-0.02.hdf5\n",
      "Epoch 00021: val_loss improved from 0.01662 to 0.01657, saving model to ./checkpoints/chk.21-0.02.hdf5\n",
      "Epoch 00022: val_loss improved from 0.01657 to 0.01643, saving model to ./checkpoints/chk.22-0.02.hdf5\n",
      "Epoch 00023: val_loss improved from 0.01643 to 0.01614, saving model to ./checkpoints/chk.23-0.02.hdf5\n",
      "Epoch 00024: val_loss did not improve\n",
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "# Compile model with adam optimizer and learning rate of .0001\n",
    "adam = Adam(lr=0.0001)\n",
    "model.compile(loss='mse',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Model will save the weights whenever validation loss improves\n",
    "checkpoint = ModelCheckpoint(filepath = './checkpoints/chk.{epoch:02d}-{val_loss:.2f}.hdf5', verbose=1, save_best_only=True, monitor='val_loss')\n",
    "\n",
    "# Stop training when validation loss fails to decrease\n",
    "callback = EarlyStopping(monitor='val_loss', patience=3, verbose=0)\n",
    "\n",
    "# Train model for 25 epochs and a batch size of 45\n",
    "model.fit(X_train,\n",
    "        y_train,\n",
    "        nb_epoch=25,\n",
    "        verbose=0,\n",
    "        batch_size=45,\n",
    "        shuffle=True,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[checkpoint, callback])\n",
    "\n",
    "json_string = model.to_json()\n",
    "with open('model.json', 'w') as jsonfile:\n",
    "    json.dump(json_string, jsonfile)\n",
    "model.save('model.h5')    \n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
